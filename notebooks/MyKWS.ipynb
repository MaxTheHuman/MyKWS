{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.7"
    },
    "colab": {
      "name": "MyKWS.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8GrhIXQQwDs1"
      },
      "source": [
        "# Homework №3"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j8BwmDqbwDs2"
      },
      "source": [
        "This homework will be dedicated to Keyword Spotting (KWS), streaming and speedup NN."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QAopZih40bAX"
      },
      "source": [
        "# Setup dependencies\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m5icSVnl-lyp",
        "outputId": "d1839fb0-3007-4682-80d0-8134f0e38063",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!pip install torch"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (1.6.0+cu101)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch) (0.16.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torch) (1.18.5)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oE3W6vwNxpDd",
        "outputId": "58427f5b-cc1b-493f-af27-63ebe2d343cb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!pip install torchaudio==0.6.0"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: torchaudio==0.6.0 in /usr/local/lib/python3.6/dist-packages (0.6.0)\n",
            "Requirement already satisfied: torch==1.6.0 in /usr/local/lib/python3.6/dist-packages (from torchaudio==0.6.0) (1.6.0+cu101)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch==1.6.0->torchaudio==0.6.0) (0.16.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torch==1.6.0->torchaudio==0.6.0) (1.18.5)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HSELnGZxyJTw",
        "outputId": "21be0021-0629-4905-d21f-c167c968b9dd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!pip install wandb"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: wandb in /usr/local/lib/python3.6/dist-packages (0.10.8)\n",
            "Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.6/dist-packages (from wandb) (5.4.8)\n",
            "Requirement already satisfied: six>=1.13.0 in /usr/local/lib/python3.6/dist-packages (from wandb) (1.15.0)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.6/dist-packages (from wandb) (3.13)\n",
            "Requirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from wandb) (2.23.0)\n",
            "Requirement already satisfied: docker-pycreds>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from wandb) (0.4.0)\n",
            "Requirement already satisfied: GitPython>=1.0.0 in /usr/local/lib/python3.6/dist-packages (from wandb) (3.1.11)\n",
            "Requirement already satisfied: protobuf>=3.12.0 in /usr/local/lib/python3.6/dist-packages (from wandb) (3.12.4)\n",
            "Requirement already satisfied: shortuuid>=0.5.0 in /usr/local/lib/python3.6/dist-packages (from wandb) (1.0.1)\n",
            "Requirement already satisfied: subprocess32>=3.5.3 in /usr/local/lib/python3.6/dist-packages (from wandb) (3.5.4)\n",
            "Requirement already satisfied: promise<3,>=2.0 in /usr/local/lib/python3.6/dist-packages (from wandb) (2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.6/dist-packages (from wandb) (2.8.1)\n",
            "Requirement already satisfied: configparser>=3.8.1 in /usr/local/lib/python3.6/dist-packages (from wandb) (5.0.1)\n",
            "Requirement already satisfied: Click>=7.0 in /usr/local/lib/python3.6/dist-packages (from wandb) (7.1.2)\n",
            "Requirement already satisfied: sentry-sdk>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from wandb) (0.19.1)\n",
            "Requirement already satisfied: watchdog>=0.8.3 in /usr/local/lib/python3.6/dist-packages (from wandb) (0.10.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.0.0->wandb) (2020.6.20)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.0.0->wandb) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.0.0->wandb) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.0.0->wandb) (1.24.3)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.6/dist-packages (from GitPython>=1.0.0->wandb) (4.0.5)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.12.0->wandb) (50.3.2)\n",
            "Requirement already satisfied: pathtools>=0.1.1 in /usr/local/lib/python3.6/dist-packages (from watchdog>=0.8.3->wandb) (0.1.2)\n",
            "Requirement already satisfied: smmap<4,>=3.0.1 in /usr/local/lib/python3.6/dist-packages (from gitdb<5,>=4.0.1->GitPython>=1.0.0->wandb) (3.0.4)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dM5CWCeAyMGj"
      },
      "source": [
        "import torch\n",
        "import torchaudio\n",
        "import pandas as pd\n",
        "# import multiprocessing as mp\n",
        "from torch import nn\n",
        "from matplotlib import pyplot as plt\n",
        "from torch.utils.data import Dataset, DataLoader, random_split\n",
        "from google.colab import files\n",
        "\n",
        "# %pylab inline\n",
        "# from itertools import islice\n",
        "# from scipy.signal import hann\n",
        "# from scipy.io import wavfile\n"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MUiyr8V2yn_f",
        "outputId": "4fea0684-bc5b-4942-9e4b-9d2021425b76",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 619
        }
      },
      "source": [
        "import wandb\n",
        "!wandb login 32f7df3c332802b239b3a621db53985fe17d319e\n",
        "wandb.init(project=\"kws-implementation\")"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mmaxthehuman\u001b[0m (use `wandb login --relogin` to force relogin)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "                Tracking run with wandb version 0.10.8<br/>\n",
              "                Syncing run <strong style=\"color:#cdcd00\">rare-galaxy-25</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
              "                Project page: <a href=\"https://wandb.ai/maxthehuman/kws-implementation\" target=\"_blank\">https://wandb.ai/maxthehuman/kws-implementation</a><br/>\n",
              "                Run page: <a href=\"https://wandb.ai/maxthehuman/kws-implementation/runs/1svru9b1\" target=\"_blank\">https://wandb.ai/maxthehuman/kws-implementation/runs/1svru9b1</a><br/>\n",
              "                Run data is saved locally in <code>wandb/run-20201102_181502-1svru9b1</code><br/><br/>\n",
              "            "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<wandb.sdk.wandb_run.Run at 0x7efed99bbeb8>"
            ],
            "text/html": [
              "<h1>Run(1svru9b1)</h1><p></p><iframe src=\"https://wandb.ai/maxthehuman/kws-implementation/runs/1svru9b1\" style=\"border:none;width:100%;height:400px\"></iframe>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WtYqBlJfYCey"
      },
      "source": [
        "# Config"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fZsgoRHlyoLH",
        "outputId": "00d9db25-d612-40e7-da52-1167ae6d45c6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "use_cuda = torch.cuda.is_available()\n",
        "torch.manual_seed(7)\n",
        "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
        "print(device)\n",
        "\n",
        "batch_size = 32\n",
        "epochs = 200\n",
        "n_mels = 40\n",
        "\n",
        "freq_mask_param = 15\n",
        "time_mask_param = 10"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cuda\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RLP2EEZOwDs3"
      },
      "source": [
        "# Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D-CbnBaCwDs4",
        "outputId": "7b17b605-4860-4ca0-bc44-af7f09532718",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "import os\n",
        "datadir = \"speech_commands\"\n",
        "\n",
        "!wget http://download.tensorflow.org/data/speech_commands_v0.01.tar.gz -O speech_commands_v0.01.tar.gz\n",
        "# alternative url: https://www.dropbox.com/s/j95n278g48bcbta/speech_commands_v0.01.tar.gz?dl=1\n",
        "!mkdir {datadir} && tar -C {datadir} -xvzf speech_commands_v0.01.tar.gz 1> log\n",
        "\n",
        "samples_by_target = {\n",
        "    cls: [os.path.join(datadir, cls, name) for name in os.listdir(\"./speech_commands/{}\".format(cls))]\n",
        "    for cls in os.listdir(datadir)\n",
        "    if os.path.isdir(os.path.join(datadir, cls))\n",
        "}\n",
        "print('Classes:', ', '.join(sorted(samples_by_target.keys())[1:]))"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-11-02 18:15:03--  http://download.tensorflow.org/data/speech_commands_v0.01.tar.gz\n",
            "Resolving download.tensorflow.org (download.tensorflow.org)... 74.125.20.128, 2607:f8b0:400e:c09::80\n",
            "Connecting to download.tensorflow.org (download.tensorflow.org)|74.125.20.128|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1489096277 (1.4G) [application/gzip]\n",
            "Saving to: ‘speech_commands_v0.01.tar.gz’\n",
            "\n",
            "speech_commands_v0. 100%[===================>]   1.39G   199MB/s    in 7.6s    \n",
            "\n",
            "2020-11-02 18:15:10 (188 MB/s) - ‘speech_commands_v0.01.tar.gz’ saved [1489096277/1489096277]\n",
            "\n",
            "mkdir: cannot create directory ‘speech_commands’: File exists\n",
            "Classes: bed, bird, cat, dog, down, eight, five, four, go, happy, house, left, marvin, nine, no, off, on, one, right, seven, sheila, six, stop, three, tree, two, up, wow, yes, zero\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tpcVnMW_wDs8"
      },
      "source": [
        "    Choose from 1 to 3 keywords to your liking, and use the rest as negative examples.\n",
        "    We recommend to use sheila and/or marvin."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gyQXhF09BJxu"
      },
      "source": [
        "###Let's use \"marvin\""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rtMuy0_CNZlX",
        "outputId": "5eaba094-fc2d-4cec-b658-e504df218235",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "for key in samples_by_target.keys():\n",
        "  print(key, len(samples_by_target[key]))"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "yes 2377\n",
            "cat 1733\n",
            "six 2369\n",
            "happy 1742\n",
            "seven 2377\n",
            "left 2353\n",
            "no 2375\n",
            "stop 2380\n",
            "right 2367\n",
            "wow 1745\n",
            "_background_noise_ 7\n",
            "zero 2376\n",
            "marvin 1746\n",
            "dog 1746\n",
            "two 2373\n",
            "nine 2364\n",
            "tree 1733\n",
            "sheila 1734\n",
            "three 2356\n",
            "eight 2352\n",
            "house 1750\n",
            "on 2367\n",
            "bed 1713\n",
            "one 2370\n",
            "five 2357\n",
            "four 2372\n",
            "up 2375\n",
            "go 2372\n",
            "down 2359\n",
            "bird 1731\n",
            "off 2357\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ncI3fy-pQ4C2",
        "outputId": "1bd17185-6afc-45c9-9582-9f9df7a2535c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "len(samples_by_target)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "31"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WD2dqgTBOTip",
        "outputId": "24cd96a6-6e13-4cfc-fe72-f1d03eeb2e5c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "len(samples_by_target['marvin'])"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1746"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nR6AqeksIQZZ"
      },
      "source": [
        "### To balance marvin and non-marvin class, knowing that there are 29 other keywords, we'll take first len(marvin) / 29 tracks for each non-marvin keyword"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GLRKYbLZ5hk4"
      },
      "source": [
        "COLUMN_NAMES=['wav_filename', 'class']\n",
        "marvin_df = pd.DataFrame(columns=COLUMN_NAMES)\n",
        "non_marvin_df = pd.DataFrame(columns=COLUMN_NAMES)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zcCut-Qz8fUW"
      },
      "source": [
        "i = 0\n",
        "for filename in samples_by_target['marvin']:\n",
        "  marvin_df.loc[i] = [filename, 1]\n",
        "  i += 1\n",
        "\n",
        "needed_len = len(samples_by_target['marvin']) // 29  # so that dataset contains equal quantity of two classes\n",
        "i = 0\n",
        "for key in samples_by_target.keys():\n",
        "  if key != '_background_noise_' and key != 'marvin':\n",
        "    for filename in samples_by_target[key][0:needed_len]:\n",
        "      non_marvin_df.loc[i] = [filename, 0]\n",
        "      i += 1"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pfYsTPD0CM85"
      },
      "source": [
        "marvin_df['class'] = marvin_df['class'].astype(int)\n",
        "non_marvin_df['class'] = non_marvin_df['class'].astype(int)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pdk_geyw9J3Q",
        "outputId": "d216ad21-3d4c-4cc6-c588-868e35004b40",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        }
      },
      "source": [
        "marvin_df"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>wav_filename</th>\n",
              "      <th>class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>speech_commands/marvin/682e1687_nohash_1.wav</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>speech_commands/marvin/881583a6_nohash_0.wav</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>speech_commands/marvin/7014b07e_nohash_2.wav</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>speech_commands/marvin/a527cb3c_nohash_1.wav</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>speech_commands/marvin/98447c43_nohash_0.wav</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1741</th>\n",
              "      <td>speech_commands/marvin/300384f0_nohash_0.wav</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1742</th>\n",
              "      <td>speech_commands/marvin/c0e8f5a1_nohash_1.wav</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1743</th>\n",
              "      <td>speech_commands/marvin/4f2ab70c_nohash_0.wav</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1744</th>\n",
              "      <td>speech_commands/marvin/65d14087_nohash_1.wav</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1745</th>\n",
              "      <td>speech_commands/marvin/f2dd248e_nohash_1.wav</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1746 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                      wav_filename  class\n",
              "0     speech_commands/marvin/682e1687_nohash_1.wav      1\n",
              "1     speech_commands/marvin/881583a6_nohash_0.wav      1\n",
              "2     speech_commands/marvin/7014b07e_nohash_2.wav      1\n",
              "3     speech_commands/marvin/a527cb3c_nohash_1.wav      1\n",
              "4     speech_commands/marvin/98447c43_nohash_0.wav      1\n",
              "...                                            ...    ...\n",
              "1741  speech_commands/marvin/300384f0_nohash_0.wav      1\n",
              "1742  speech_commands/marvin/c0e8f5a1_nohash_1.wav      1\n",
              "1743  speech_commands/marvin/4f2ab70c_nohash_0.wav      1\n",
              "1744  speech_commands/marvin/65d14087_nohash_1.wav      1\n",
              "1745  speech_commands/marvin/f2dd248e_nohash_1.wav      1\n",
              "\n",
              "[1746 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7jeExs_-Fbo1",
        "outputId": "1c0e059f-2dd9-4276-a6f9-447d60f31827",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        }
      },
      "source": [
        "non_marvin_df"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>wav_filename</th>\n",
              "      <th>class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>speech_commands/yes/ce9410da_nohash_1.wav</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>speech_commands/yes/e53139ad_nohash_3.wav</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>speech_commands/yes/df1d5024_nohash_2.wav</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>speech_commands/yes/333784b7_nohash_1.wav</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>speech_commands/yes/16d41d07_nohash_0.wav</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1735</th>\n",
              "      <td>speech_commands/off/1e4064b8_nohash_1.wav</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1736</th>\n",
              "      <td>speech_commands/off/64574a99_nohash_0.wav</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1737</th>\n",
              "      <td>speech_commands/off/ffd2ba2f_nohash_2.wav</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1738</th>\n",
              "      <td>speech_commands/off/cb2929ce_nohash_3.wav</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1739</th>\n",
              "      <td>speech_commands/off/c79159aa_nohash_0.wav</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1740 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                   wav_filename  class\n",
              "0     speech_commands/yes/ce9410da_nohash_1.wav      0\n",
              "1     speech_commands/yes/e53139ad_nohash_3.wav      0\n",
              "2     speech_commands/yes/df1d5024_nohash_2.wav      0\n",
              "3     speech_commands/yes/333784b7_nohash_1.wav      0\n",
              "4     speech_commands/yes/16d41d07_nohash_0.wav      0\n",
              "...                                         ...    ...\n",
              "1735  speech_commands/off/1e4064b8_nohash_1.wav      0\n",
              "1736  speech_commands/off/64574a99_nohash_0.wav      0\n",
              "1737  speech_commands/off/ffd2ba2f_nohash_2.wav      0\n",
              "1738  speech_commands/off/cb2929ce_nohash_3.wav      0\n",
              "1739  speech_commands/off/c79159aa_nohash_0.wav      0\n",
              "\n",
              "[1740 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f9HI8PP9Fdrm",
        "outputId": "c0d0571a-891d-4d8f-8057-64b28534d19d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "train_marvin = marvin_df.sample(frac=0.9, random_state=21)\n",
        "test_marvin = marvin_df.drop(train_marvin.index)\n",
        "\n",
        "train_non_marvin = non_marvin_df.sample(frac=0.9, random_state=21)\n",
        "test_non_marvin = non_marvin_df.drop(train_non_marvin.index)\n",
        "\n",
        "train_set = pd.concat([train_marvin, train_non_marvin])\n",
        "test_set = pd.concat([test_marvin, test_non_marvin])\n",
        "\n",
        "train_set = train_set.sample(frac=1, random_state=22).reset_index(drop=True)\n",
        "test_set = test_set.sample(frac=1, random_state=22).reset_index(drop=True)\n",
        "\n",
        "print(\"train set size:\", len(train_set), \"\\ntest set size:\", len(test_set))"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "train set size: 3137 \n",
            "test set size: 349\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x7ChzoFD0GBS"
      },
      "source": [
        "mel_transform = torchaudio.transforms.MelSpectrogram(\n",
        "    sample_rate=22050,\n",
        "    n_fft=1024,\n",
        "    win_length=1024,\n",
        "    hop_length=256,\n",
        "    f_min=0,\n",
        "    f_max=8000,\n",
        "    n_mels=n_mels).to(device)"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3mtvTDEj1tZj"
      },
      "source": [
        "# import IPython\n",
        "\n",
        "# IPython.display.Audio(\"speech_commands/marvin/cc592808_nohash_0.wav\")  "
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7RhaI-AoX3Ji"
      },
      "source": [
        "class MyDataset(Dataset):\n",
        "    def __init__(self, data):\n",
        "        super(MyDataset, self).__init__()\n",
        "        self._data = data\n",
        "\n",
        "    def __getitem__(self, index: int):\n",
        "        wav_filename, true_class = self._data.iloc[index]\n",
        "        # print(\"file:\", wav_filename)\n",
        "        # path_to_file = path_to_dataset + \"wavs/\" + wav_filename + \".wav\"\n",
        "\n",
        "        waveform, sample_rate = torchaudio.load(wav_filename)\n",
        "        waveform = waveform.to(device)\n",
        "        spectrogram = mel_transform(waveform)\n",
        "        spectrogram = torch.log(spectrogram + 1e-9)\n",
        "\n",
        "        return spectrogram, true_class\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self._data)"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mHur-bjgX3RU"
      },
      "source": [
        "train_dataset = MyDataset(train_set)\n",
        "test_dataset = MyDataset(test_set)"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DyAPmzXnX3Nc"
      },
      "source": [
        "# plt.figure(figsize=(20, 5))\n",
        "# spectrogram, true_class = train_dataset.__getitem__(0)\n",
        "# print(true_class)\n",
        "# plt.imshow(spectrogram.cpu().squeeze())\n",
        "# plt.show()"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "30-tRGTyBlBw"
      },
      "source": [
        "def augment(waveform):\n",
        "    freq_transform = torchaudio.transforms.FrequencyMasking(freq_mask_param=freq_mask_param)\n",
        "    time_transform = torchaudio.transforms.TimeMasking(time_mask_param=time_mask_param)\n",
        "    return time_transform(freq_transform(waveform))"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OVxLC2AdB0lI"
      },
      "source": [
        "def collate_sequences(batch, is_test = False):\n",
        "    specs = []\n",
        "    labels = []\n",
        "    specs_len = []\n",
        "    labels_len = []\n",
        "    for (log_mel_spec, true_class) in batch:\n",
        "        # print(\"true_class:\", true_class)\n",
        "        if not is_test:\n",
        "            log_mel_spec = augment(log_mel_spec)\n",
        "        specs.append(log_mel_spec.squeeze(0).transpose(0, 1))\n",
        "        # specs_len.append(log_mel_spec.shape[-1]//2)\n",
        "        # print(log_mel_spec.shape)\n",
        "        # text_in_ints = torch.Tensor(text_transform(text_in_letters))\n",
        "        labels.append(torch.LongTensor([true_class]))\n",
        "        # labels_len.append(1)\n",
        "\n",
        "    # print(\"labels before cat:\", labels)\n",
        "    specs = nn.utils.rnn.pad_sequence(sequences=specs, batch_first=True).transpose(1, 2)\n",
        "    # labels = nn.utils.rnn.pad_sequence(sequences=labels, batch_first=True)\n",
        "    labels = torch.cat(labels)\n",
        "    # print(\"labels after cat:\", labels)\n",
        "\n",
        "    return specs, labels  # , specs_len, labels_len"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DKjzwgHLEyQg"
      },
      "source": [
        "train_dataloader = DataLoader(\n",
        "            train_dataset,\n",
        "            batch_size=batch_size,\n",
        "            collate_fn=collate_sequences,\n",
        "            num_workers=0\n",
        "            # pin_memory=True\n",
        "        )\n",
        "\n",
        "test_dataloader = DataLoader(\n",
        "            test_dataset,\n",
        "            batch_size=batch_size,\n",
        "            collate_fn=lambda x: collate_sequences(x, True),\n",
        "            num_workers=0\n",
        "            # pin_memory=True\n",
        "        )"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HOZq6zNPEyOy",
        "outputId": "11eb2936-a970-4d5c-8843-fc5fdb057c6f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print(len(train_dataloader))\n",
        "print(len(test_dataloader))"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "99\n",
            "11\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wf891e3jwDs9"
      },
      "source": [
        "# Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vi-ZRMyNxU3S"
      },
      "source": [
        "class CRNNEncoder(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(CRNNEncoder, self).__init__()\n",
        "        self.cnn = nn.Conv1d(\n",
        "            in_channels=40, out_channels=64, kernel_size=20, padding=20//2\n",
        "        )\n",
        "        self.gru = nn.GRU(input_size=64, hidden_size=128)\n",
        "\n",
        "    def forward(self, x, encoder_hidden):\n",
        "\n",
        "        outputs = self.cnn(x)\n",
        "\n",
        "        outputs = torch.transpose(outputs, 0, 2)\n",
        "        outputs = torch.transpose(outputs, 1, 2)\n",
        "\n",
        "        if encoder_hidden == None:\n",
        "            outputs, hidden = self.gru(outputs)\n",
        "        else:\n",
        "            outputs, hidden = self.gru(outputs, encoder_hidden)\n",
        "\n",
        "        outputs = torch.transpose(outputs, 0, 1)\n",
        "\n",
        "        return outputs, hidden\n",
        "        \n",
        "class Attn(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Attn, self).__init__()\n",
        "        self.main_fully_connected = nn.Linear(in_features=128, out_features=64)\n",
        "        self.main_softmax = nn.Softmax(dim=-1)\n",
        "        self.tanh = nn.Tanh()\n",
        "        self.v = nn.Linear(64, 1)\n",
        "        self.middle_softmax = nn.Softmax(dim=1)\n",
        "        self.final_fully_connected = nn.Linear(in_features=128, out_features=2)\n",
        "        self.final_softmax = nn.Softmax(dim=0)\n",
        "\n",
        "    def forward(self, hiddens, single_input):\n",
        "\n",
        "        x = self.main_fully_connected(hiddens)\n",
        "        x = self.main_softmax(x)\n",
        "        x = self.tanh(x)\n",
        "\n",
        "        e = self.v(x)\n",
        "        a = self.middle_softmax(e)\n",
        "\n",
        "        outputs = []\n",
        "        for i in range(hiddens.shape[0]):\n",
        "          outputs.append(torch.mm(torch.transpose(hiddens[i], 0, 1), a[i]))\n",
        "        outputs = torch.transpose(torch.cat(outputs, dim=1), 0, 1)\n",
        "\n",
        "        outputs = self.final_fully_connected(outputs)\n",
        "\n",
        "        if not single_input:\n",
        "          outputs = self.final_softmax(outputs)\n",
        "\n",
        "        return outputs\n",
        "\n",
        "\n",
        "class KWS(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(KWS, self).__init__()\n",
        "        self.encoder = CRNNEncoder()\n",
        "        self.attention = Attn()\n",
        "\n",
        "    def forward(self, x, encoder_hidden = None, single_input = False):\n",
        "\n",
        "        outputs, hidden = self.encoder(x, encoder_hidden)\n",
        "        x = self.attention(outputs, single_input)\n",
        "\n",
        "        return x, hidden\n",
        "        "
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SmuW7XbT23IM"
      },
      "source": [
        "# Train-Test pipeline"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W3PwLwnX2M_C",
        "outputId": "373030e3-50b6-459d-e943-dd91a6db8732",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "model=KWS().to(device)\n",
        "wandb.watch(model)\n",
        "\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=5e-4)\n",
        "criterion = nn.CrossEntropyLoss().to(device)\n",
        "\n",
        "total_params = sum(p.numel() for p in model.parameters())\n",
        "print(total_params)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "134339\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ysr_iiJf4ejR"
      },
      "source": [
        "def train(model, train_dataloader, criterion, optimizer, epoch):\n",
        "    model.train()\n",
        "    data_len = len(train_dataloader.dataset)\n",
        "    losses = []\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    fa = 0\n",
        "    fr = 0\n",
        "    for batch_idx, (log_mel_specs, classes) in enumerate(train_dataloader):\n",
        "        log_mel_specs = log_mel_specs.to(device)\n",
        "        classes = classes.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        output, hidden = model(log_mel_specs)  # (batch, time, n_class)\n",
        "        __, predicted = torch.max(output, dim=1)\n",
        "        correct += (predicted == classes).sum().item()\n",
        "        total += classes.shape[0]\n",
        "        for i in range(classes.shape[0]):\n",
        "          if (predicted[i] == 1 and classes[i] == 0):\n",
        "            fa += 1\n",
        "          elif (predicted[i] == 0 and classes[i] == 1):\n",
        "            fr += 1\n",
        "        \n",
        "        loss = criterion(output, classes)\n",
        "        loss.backward()\n",
        "        losses.append(loss)\n",
        "\n",
        "        optimizer.step()\n",
        "        if batch_idx == 1 and epoch % 10 == 1:\n",
        "            print('Train Epoch: {}\\tLoss: {:.6f}\\tfa/fr: {:.6f}'.format(\n",
        "                epoch, loss.item(), fa / (fr + 1e-9)))\n",
        "    return sum(losses) / len(losses), correct, fa, fr + 1e-9, total"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5rnkJJej4egy"
      },
      "source": [
        "def test(model, test_dataloader, criterion, epoch):\n",
        "    model.eval()\n",
        "    test_loss = 0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    fa = 0\n",
        "    fr = 0\n",
        "    with torch.no_grad():\n",
        "        for batch_idx, (log_mel_specs, true_class) in enumerate(test_dataloader):\n",
        "            log_mel_specs = log_mel_specs.to(device)\n",
        "            true_class = true_class.to(device)\n",
        "\n",
        "            output, hidden = model(log_mel_specs)  # (batch, time, n_class)\n",
        "            __, predicted = torch.max(output, dim=1)\n",
        "            correct += (predicted == true_class).sum().item()\n",
        "            total += true_class.shape[0]\n",
        "            for i in range(true_class.shape[0]):\n",
        "              if (predicted[i] == 1 and true_class[i] == 0):\n",
        "                fa += 1\n",
        "              elif (predicted[i] == 0 and true_class[i] == 1):\n",
        "                fr += 1\n",
        "            loss = criterion(output, true_class)\n",
        "            test_loss += loss.item() / len(test_dataloader)\n",
        "\n",
        "    print('Test set average loss: {:.4f}\\n'.format(test_loss))\n",
        "    print('Test set fa/fr: {:.4f}\\n'.format(fa / (fr + 1e-9)))\n",
        "    return test_loss, correct, fa, fr + 1e-9, total\n"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hK0HoN1unzIa"
      },
      "source": [
        "# weights_file = wandb.restore('weights.pt')\n",
        "# model.load_state_dict(torch.load('weights.pt'))"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ehVTjFr44eev",
        "outputId": "aa950b9e-55f4-452b-fdb7-feeca4d79e24",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "for epoch in range(epochs):\n",
        "  print(\"epoch:\", epoch)\n",
        "  train_avg_loss, train_correct, train_fa, train_fr, train_total = train(model, train_dataloader, criterion, optimizer, epoch)\n",
        "  print(\"train accuracy:\", train_correct / train_total)\n",
        "  test_avg_loss, test_correct, test_fa, test_fr, test_total = test(model, test_dataloader, criterion, epoch)\n",
        "  print(\"test accuracy:\", test_correct / test_total)\n",
        "  wandb.log({\"Train loss\": train_avg_loss,\n",
        "             \"Test loss\": test_avg_loss,\n",
        "             \"Train accuracy\": train_correct / train_total,\n",
        "             \"Test accuracy\": test_correct / test_total,\n",
        "             \"Train fa\": train_fa / train_total,\n",
        "             \"Test fa\": test_fa / test_total,\n",
        "             \"Train fr\": train_fr / train_total,\n",
        "             \"Test fr\": test_fr / test_total})\n",
        "\n",
        "model = model.to(\"cpu\")\n",
        "torch.save(model.state_dict(), os.path.join(wandb.run.dir, 'weights.pt'))\n",
        "wandb.save('weights.h5')\n",
        "# files.download('model_state_dict.pt')\n",
        "model = model.to(device)\n",
        "print(\"Saved model at last epoch\")"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "epoch: 0\n",
            "train accuracy: 0.6687918393369461\n",
            "Test set average loss: 0.6714\n",
            "\n",
            "Test set fa/fr: 0.7869\n",
            "\n",
            "test accuracy: 0.6876790830945558\n",
            "epoch: 1\n",
            "Train Epoch: 1\tLoss: 0.675598\tfa/fr: 1.000000\n",
            "train accuracy: 0.7299968122409946\n",
            "Test set average loss: 0.6670\n",
            "\n",
            "Test set fa/fr: 1.0000\n",
            "\n",
            "test accuracy: 0.7822349570200573\n",
            "epoch: 2\n",
            "train accuracy: 0.8042715970672617\n",
            "Test set average loss: 0.6651\n",
            "\n",
            "Test set fa/fr: 0.6190\n",
            "\n",
            "test accuracy: 0.8051575931232091\n",
            "epoch: 3\n",
            "train accuracy: 0.8390181702263309\n",
            "Test set average loss: 0.6647\n",
            "\n",
            "Test set fa/fr: 0.5294\n",
            "\n",
            "test accuracy: 0.8510028653295129\n",
            "epoch: 4\n",
            "train accuracy: 0.8412496015301243\n",
            "Test set average loss: 0.6641\n",
            "\n",
            "Test set fa/fr: 0.8333\n",
            "\n",
            "test accuracy: 0.8424068767908309\n",
            "epoch: 5\n",
            "train accuracy: 0.8645202422696844\n",
            "Test set average loss: 0.6640\n",
            "\n",
            "Test set fa/fr: 0.3929\n",
            "\n",
            "test accuracy: 0.8882521489971347\n",
            "epoch: 6\n",
            "train accuracy: 0.8645202422696844\n",
            "Test set average loss: 0.6639\n",
            "\n",
            "Test set fa/fr: 0.5333\n",
            "\n",
            "test accuracy: 0.8681948424068768\n",
            "epoch: 7\n",
            "train accuracy: 0.8769525023908192\n",
            "Test set average loss: 0.6638\n",
            "\n",
            "Test set fa/fr: 0.8333\n",
            "\n",
            "test accuracy: 0.8739255014326648\n",
            "epoch: 8\n",
            "train accuracy: 0.8769525023908192\n",
            "Test set average loss: 0.6640\n",
            "\n",
            "Test set fa/fr: 1.6316\n",
            "\n",
            "test accuracy: 0.8567335243553008\n",
            "epoch: 9\n",
            "train accuracy: 0.8603761555626395\n",
            "Test set average loss: 0.6636\n",
            "\n",
            "Test set fa/fr: 0.3750\n",
            "\n",
            "test accuracy: 0.9054441260744985\n",
            "epoch: 10\n",
            "train accuracy: 0.8932100733184571\n",
            "Test set average loss: 0.6635\n",
            "\n",
            "Test set fa/fr: 0.9412\n",
            "\n",
            "test accuracy: 0.9054441260744985\n",
            "epoch: 11\n",
            "Train Epoch: 11\tLoss: 0.664314\tfa/fr: 1.333333\n",
            "train accuracy: 0.8995855913292955\n",
            "Test set average loss: 0.6633\n",
            "\n",
            "Test set fa/fr: 0.7000\n",
            "\n",
            "test accuracy: 0.9025787965616046\n",
            "epoch: 12\n",
            "train accuracy: 0.9030921262352566\n",
            "Test set average loss: 0.6632\n",
            "\n",
            "Test set fa/fr: 0.5714\n",
            "\n",
            "test accuracy: 0.9054441260744985\n",
            "epoch: 13\n",
            "train accuracy: 0.9043672298374242\n",
            "Test set average loss: 0.6633\n",
            "\n",
            "Test set fa/fr: 0.6522\n",
            "\n",
            "test accuracy: 0.8911174785100286\n",
            "epoch: 14\n",
            "train accuracy: 0.897672935926044\n",
            "Test set average loss: 0.6631\n",
            "\n",
            "Test set fa/fr: 0.9375\n",
            "\n",
            "test accuracy: 0.9111747851002865\n",
            "epoch: 15\n",
            "train accuracy: 0.9110615237488046\n",
            "Test set average loss: 0.6630\n",
            "\n",
            "Test set fa/fr: 0.6842\n",
            "\n",
            "test accuracy: 0.9083094555873925\n",
            "epoch: 16\n",
            "train accuracy: 0.9040484539368824\n",
            "Test set average loss: 0.6632\n",
            "\n",
            "Test set fa/fr: 0.2273\n",
            "\n",
            "test accuracy: 0.9226361031518625\n",
            "epoch: 17\n",
            "train accuracy: 0.925087663372649\n",
            "Test set average loss: 0.6629\n",
            "\n",
            "Test set fa/fr: 0.4444\n",
            "\n",
            "test accuracy: 0.9255014326647565\n",
            "epoch: 18\n",
            "train accuracy: 0.9126554032515142\n",
            "Test set average loss: 0.6631\n",
            "\n",
            "Test set fa/fr: 1.3333\n",
            "\n",
            "test accuracy: 0.8997134670487106\n",
            "epoch: 19\n",
            "train accuracy: 0.9203060248645203\n",
            "Test set average loss: 0.6629\n",
            "\n",
            "Test set fa/fr: 0.6250\n",
            "\n",
            "test accuracy: 0.9255014326647565\n",
            "epoch: 20\n",
            "train accuracy: 0.9305068536818617\n",
            "Test set average loss: 0.6629\n",
            "\n",
            "Test set fa/fr: 0.4000\n",
            "\n",
            "test accuracy: 0.9398280802292264\n",
            "epoch: 21\n",
            "Train Epoch: 21\tLoss: 0.663668\tfa/fr: 0.750000\n",
            "train accuracy: 0.9305068536818617\n",
            "Test set average loss: 0.6628\n",
            "\n",
            "Test set fa/fr: 0.9286\n",
            "\n",
            "test accuracy: 0.9226361031518625\n",
            "epoch: 22\n",
            "train accuracy: 0.9228562320688556\n",
            "Test set average loss: 0.6627\n",
            "\n",
            "Test set fa/fr: 0.2222\n",
            "\n",
            "test accuracy: 0.9369627507163324\n",
            "epoch: 23\n",
            "train accuracy: 0.933057060886197\n",
            "Test set average loss: 0.6630\n",
            "\n",
            "Test set fa/fr: 0.3333\n",
            "\n",
            "test accuracy: 0.9312320916905444\n",
            "epoch: 24\n",
            "train accuracy: 0.9234937838699394\n",
            "Test set average loss: 0.6627\n",
            "\n",
            "Test set fa/fr: 0.1667\n",
            "\n",
            "test accuracy: 0.9398280802292264\n",
            "epoch: 25\n",
            "train accuracy: 0.9340133885878228\n",
            "Test set average loss: 0.6626\n",
            "\n",
            "Test set fa/fr: 0.5556\n",
            "\n",
            "test accuracy: 0.9197707736389685\n",
            "epoch: 26\n",
            "train accuracy: 0.9209435766656041\n",
            "Test set average loss: 0.6626\n",
            "\n",
            "Test set fa/fr: 0.4667\n",
            "\n",
            "test accuracy: 0.9369627507163324\n",
            "epoch: 27\n",
            "train accuracy: 0.933375836786739\n",
            "Test set average loss: 0.6628\n",
            "\n",
            "Test set fa/fr: 0.6111\n",
            "\n",
            "test accuracy: 0.9169054441260746\n",
            "epoch: 28\n",
            "train accuracy: 0.9305068536818617\n",
            "Test set average loss: 0.6628\n",
            "\n",
            "Test set fa/fr: 0.3000\n",
            "\n",
            "test accuracy: 0.9255014326647565\n",
            "epoch: 29\n",
            "train accuracy: 0.9311444054829455\n",
            "Test set average loss: 0.6626\n",
            "\n",
            "Test set fa/fr: 0.3125\n",
            "\n",
            "test accuracy: 0.9398280802292264\n",
            "epoch: 30\n",
            "train accuracy: 0.9238125597704814\n",
            "Test set average loss: 0.6626\n",
            "\n",
            "Test set fa/fr: 0.2500\n",
            "\n",
            "test accuracy: 0.9426934097421203\n",
            "epoch: 31\n",
            "Train Epoch: 31\tLoss: 0.662997\tfa/fr: 1.000000\n",
            "train accuracy: 0.933375836786739\n",
            "Test set average loss: 0.6626\n",
            "\n",
            "Test set fa/fr: 0.3846\n",
            "\n",
            "test accuracy: 0.9484240687679083\n",
            "epoch: 32\n",
            "train accuracy: 0.9391138029964935\n",
            "Test set average loss: 0.6627\n",
            "\n",
            "Test set fa/fr: 0.0588\n",
            "\n",
            "test accuracy: 0.9484240687679083\n",
            "epoch: 33\n",
            "train accuracy: 0.9368823716927001\n",
            "Test set average loss: 0.6627\n",
            "\n",
            "Test set fa/fr: 0.2667\n",
            "\n",
            "test accuracy: 0.9455587392550143\n",
            "epoch: 34\n",
            "train accuracy: 0.944851769206248\n",
            "Test set average loss: 0.6626\n",
            "\n",
            "Test set fa/fr: 0.4667\n",
            "\n",
            "test accuracy: 0.9369627507163324\n",
            "epoch: 35\n",
            "train accuracy: 0.941026458399745\n",
            "Test set average loss: 0.6629\n",
            "\n",
            "Test set fa/fr: 0.1739\n",
            "\n",
            "test accuracy: 0.9226361031518625\n",
            "epoch: 36\n",
            "train accuracy: 0.9445329933057061\n",
            "Test set average loss: 0.6627\n",
            "\n",
            "Test set fa/fr: 0.1765\n",
            "\n",
            "test accuracy: 0.9426934097421203\n",
            "epoch: 37\n",
            "train accuracy: 0.9416640102008288\n",
            "Test set average loss: 0.6627\n",
            "\n",
            "Test set fa/fr: 0.1176\n",
            "\n",
            "test accuracy: 0.9455587392550143\n",
            "epoch: 38\n",
            "train accuracy: 0.9384762511954097\n",
            "Test set average loss: 0.6626\n",
            "\n",
            "Test set fa/fr: 0.3333\n",
            "\n",
            "test accuracy: 0.9426934097421203\n",
            "epoch: 39\n",
            "train accuracy: 0.9435766656040804\n",
            "Test set average loss: 0.6626\n",
            "\n",
            "Test set fa/fr: 0.1667\n",
            "\n",
            "test accuracy: 0.9598853868194842\n",
            "epoch: 40\n",
            "train accuracy: 0.9445329933057061\n",
            "Test set average loss: 0.6627\n",
            "\n",
            "Test set fa/fr: 0.3077\n",
            "\n",
            "test accuracy: 0.9512893982808023\n",
            "epoch: 41\n",
            "Train Epoch: 41\tLoss: 0.663139\tfa/fr: 0.750000\n",
            "train accuracy: 0.9426203379024546\n",
            "Test set average loss: 0.6626\n",
            "\n",
            "Test set fa/fr: 0.5000\n",
            "\n",
            "test accuracy: 0.9398280802292264\n",
            "epoch: 42\n",
            "train accuracy: 0.9289129741791521\n",
            "Test set average loss: 0.6626\n",
            "\n",
            "Test set fa/fr: 0.0667\n",
            "\n",
            "test accuracy: 0.9541547277936963\n",
            "epoch: 43\n",
            "train accuracy: 0.9384762511954097\n",
            "Test set average loss: 0.6627\n",
            "\n",
            "Test set fa/fr: 0.3000\n",
            "\n",
            "test accuracy: 0.9255014326647565\n",
            "epoch: 44\n",
            "train accuracy: 0.9314631813834874\n",
            "Test set average loss: 0.6628\n",
            "\n",
            "Test set fa/fr: 0.4000\n",
            "\n",
            "test accuracy: 0.9398280802292264\n",
            "epoch: 45\n",
            "train accuracy: 0.9470832005100415\n",
            "Test set average loss: 0.6626\n",
            "\n",
            "Test set fa/fr: 0.2941\n",
            "\n",
            "test accuracy: 0.9369627507163324\n",
            "epoch: 46\n",
            "train accuracy: 0.9432578897035384\n",
            "Test set average loss: 0.6626\n",
            "\n",
            "Test set fa/fr: 0.1579\n",
            "\n",
            "test accuracy: 0.9369627507163324\n",
            "epoch: 47\n",
            "train accuracy: 0.9419827861013708\n",
            "Test set average loss: 0.6626\n",
            "\n",
            "Test set fa/fr: 0.2143\n",
            "\n",
            "test accuracy: 0.9512893982808023\n",
            "epoch: 48\n",
            "train accuracy: 0.9365635957921581\n",
            "Test set average loss: 0.6627\n",
            "\n",
            "Test set fa/fr: 0.0556\n",
            "\n",
            "test accuracy: 0.9455587392550143\n",
            "epoch: 49\n",
            "train accuracy: 0.9368823716927001\n",
            "Test set average loss: 0.6627\n",
            "\n",
            "Test set fa/fr: 0.4615\n",
            "\n",
            "test accuracy: 0.9455587392550143\n",
            "epoch: 50\n",
            "train accuracy: 0.9547338221230475\n",
            "Test set average loss: 0.6626\n",
            "\n",
            "Test set fa/fr: 0.2632\n",
            "\n",
            "test accuracy: 0.9312320916905444\n",
            "epoch: 51\n",
            "Train Epoch: 51\tLoss: 0.663277\tfa/fr: 0.750000\n",
            "train accuracy: 0.9381574752948677\n",
            "Test set average loss: 0.6626\n",
            "\n",
            "Test set fa/fr: 0.1333\n",
            "\n",
            "test accuracy: 0.9512893982808023\n",
            "epoch: 52\n",
            "train accuracy: 0.9474019764105833\n",
            "Test set average loss: 0.6626\n",
            "\n",
            "Test set fa/fr: 0.3571\n",
            "\n",
            "test accuracy: 0.9455587392550143\n",
            "epoch: 53\n",
            "train accuracy: 0.9486770800127511\n",
            "Test set average loss: 0.6626\n",
            "\n",
            "Test set fa/fr: 0.3846\n",
            "\n",
            "test accuracy: 0.9484240687679083\n",
            "epoch: 54\n",
            "train accuracy: 0.932738284985655\n",
            "Test set average loss: 0.6629\n",
            "\n",
            "Test set fa/fr: 0.1111\n",
            "\n",
            "test accuracy: 0.9426934097421203\n",
            "epoch: 55\n",
            "train accuracy: 0.9298693018807778\n",
            "Test set average loss: 0.6626\n",
            "\n",
            "Test set fa/fr: 0.3750\n",
            "\n",
            "test accuracy: 0.9369627507163324\n",
            "epoch: 56\n",
            "train accuracy: 0.9314631813834874\n",
            "Test set average loss: 0.6625\n",
            "\n",
            "Test set fa/fr: 0.1250\n",
            "\n",
            "test accuracy: 0.9484240687679083\n",
            "epoch: 57\n",
            "train accuracy: 0.9352884921899904\n",
            "Test set average loss: 0.6625\n",
            "\n",
            "Test set fa/fr: 0.1333\n",
            "\n",
            "test accuracy: 0.9512893982808023\n",
            "epoch: 58\n",
            "train accuracy: 0.9356072680905324\n",
            "Test set average loss: 0.6625\n",
            "\n",
            "Test set fa/fr: 0.9231\n",
            "\n",
            "test accuracy: 0.9283667621776505\n",
            "epoch: 59\n",
            "train accuracy: 0.9365635957921581\n",
            "Test set average loss: 0.6627\n",
            "\n",
            "Test set fa/fr: 0.1111\n",
            "\n",
            "test accuracy: 0.9426934097421203\n",
            "epoch: 60\n",
            "train accuracy: 0.941026458399745\n",
            "Test set average loss: 0.6626\n",
            "\n",
            "Test set fa/fr: 0.6923\n",
            "\n",
            "test accuracy: 0.9369627507163324\n",
            "epoch: 61\n",
            "Train Epoch: 61\tLoss: 0.663070\tfa/fr: 2.000000\n",
            "train accuracy: 0.9391138029964935\n",
            "Test set average loss: 0.6627\n",
            "\n",
            "Test set fa/fr: 0.3571\n",
            "\n",
            "test accuracy: 0.9455587392550143\n",
            "epoch: 62\n",
            "train accuracy: 0.9470832005100415\n",
            "Test set average loss: 0.6626\n",
            "\n",
            "Test set fa/fr: 0.1818\n",
            "\n",
            "test accuracy: 0.9627507163323782\n",
            "epoch: 63\n",
            "train accuracy: 0.9540962703219636\n",
            "Test set average loss: 0.6624\n",
            "\n",
            "Test set fa/fr: 0.4000\n",
            "\n",
            "test accuracy: 0.9598853868194842\n",
            "epoch: 64\n",
            "train accuracy: 0.9499521836149187\n",
            "Test set average loss: 0.6624\n",
            "\n",
            "Test set fa/fr: 0.3333\n",
            "\n",
            "test accuracy: 0.9656160458452722\n",
            "epoch: 65\n",
            "train accuracy: 0.9432578897035384\n",
            "Test set average loss: 0.6626\n",
            "\n",
            "Test set fa/fr: 0.2500\n",
            "\n",
            "test accuracy: 0.9570200573065902\n",
            "epoch: 66\n",
            "train accuracy: 0.9489958559132929\n",
            "Test set average loss: 0.6627\n",
            "\n",
            "Test set fa/fr: 0.0769\n",
            "\n",
            "test accuracy: 0.9598853868194842\n",
            "epoch: 67\n",
            "train accuracy: 0.9534587185208798\n",
            "Test set average loss: 0.6626\n",
            "\n",
            "Test set fa/fr: 0.3000\n",
            "\n",
            "test accuracy: 0.9627507163323782\n",
            "epoch: 68\n",
            "train accuracy: 0.9515460631176283\n",
            "Test set average loss: 0.6629\n",
            "\n",
            "Test set fa/fr: 0.0588\n",
            "\n",
            "test accuracy: 0.9484240687679083\n",
            "epoch: 69\n",
            "train accuracy: 0.9416640102008288\n",
            "Test set average loss: 0.6625\n",
            "\n",
            "Test set fa/fr: 0.6000\n",
            "\n",
            "test accuracy: 0.9541547277936963\n",
            "epoch: 70\n",
            "train accuracy: 0.9579215811284667\n",
            "Test set average loss: 0.6625\n",
            "\n",
            "Test set fa/fr: 0.1818\n",
            "\n",
            "test accuracy: 0.9627507163323782\n",
            "epoch: 71\n",
            "Train Epoch: 71\tLoss: 0.662833\tfa/fr: 0.500000\n",
            "train accuracy: 0.9442142174051642\n",
            "Test set average loss: 0.6626\n",
            "\n",
            "Test set fa/fr: 0.1429\n",
            "\n",
            "test accuracy: 0.9541547277936963\n",
            "epoch: 72\n",
            "train accuracy: 0.9467644246094995\n",
            "Test set average loss: 0.6625\n",
            "\n",
            "Test set fa/fr: 0.3333\n",
            "\n",
            "test accuracy: 0.9312320916905444\n",
            "epoch: 73\n",
            "train accuracy: 0.9372011475932419\n",
            "Test set average loss: 0.6626\n",
            "\n",
            "Test set fa/fr: 0.0714\n",
            "\n",
            "test accuracy: 0.9570200573065902\n",
            "epoch: 74\n",
            "train accuracy: 0.9464456487089576\n",
            "Test set average loss: 0.6626\n",
            "\n",
            "Test set fa/fr: 0.1667\n",
            "\n",
            "test accuracy: 0.9598853868194842\n",
            "epoch: 75\n",
            "train accuracy: 0.9493146318138349\n",
            "Test set average loss: 0.6626\n",
            "\n",
            "Test set fa/fr: 0.2308\n",
            "\n",
            "test accuracy: 0.9541547277936963\n",
            "epoch: 76\n",
            "train accuracy: 0.9489958559132929\n",
            "Test set average loss: 0.6625\n",
            "\n",
            "Test set fa/fr: 0.0714\n",
            "\n",
            "test accuracy: 0.9570200573065902\n",
            "epoch: 77\n",
            "train accuracy: 0.960790564233344\n",
            "Test set average loss: 0.6625\n",
            "\n",
            "Test set fa/fr: 0.0833\n",
            "\n",
            "test accuracy: 0.9627507163323782\n",
            "epoch: 78\n",
            "train accuracy: 0.9509085113165445\n",
            "Test set average loss: 0.6626\n",
            "\n",
            "Test set fa/fr: 0.4000\n",
            "\n",
            "test accuracy: 0.9598853868194842\n",
            "epoch: 79\n",
            "train accuracy: 0.9579215811284667\n",
            "Test set average loss: 0.6625\n",
            "\n",
            "Test set fa/fr: 0.1538\n",
            "\n",
            "test accuracy: 0.9570200573065902\n",
            "epoch: 80\n",
            "train accuracy: 0.9419827861013708\n",
            "Test set average loss: 0.6625\n",
            "\n",
            "Test set fa/fr: 0.1667\n",
            "\n",
            "test accuracy: 0.9598853868194842\n",
            "epoch: 81\n",
            "Train Epoch: 81\tLoss: 0.662850\tfa/fr: 0.333333\n",
            "train accuracy: 0.9483583041122091\n",
            "Test set average loss: 0.6626\n",
            "\n",
            "Test set fa/fr: 0.0000\n",
            "\n",
            "test accuracy: 0.9598853868194842\n",
            "epoch: 82\n",
            "train accuracy: 0.9534587185208798\n",
            "Test set average loss: 0.6625\n",
            "\n",
            "Test set fa/fr: 0.4000\n",
            "\n",
            "test accuracy: 0.9598853868194842\n",
            "epoch: 83\n",
            "train accuracy: 0.9534587185208798\n",
            "Test set average loss: 0.6625\n",
            "\n",
            "Test set fa/fr: 0.3000\n",
            "\n",
            "test accuracy: 0.9627507163323782\n",
            "epoch: 84\n",
            "train accuracy: 0.9505897354160026\n",
            "Test set average loss: 0.6626\n",
            "\n",
            "Test set fa/fr: 0.1667\n",
            "\n",
            "test accuracy: 0.9598853868194842\n",
            "epoch: 85\n",
            "train accuracy: 0.9461268728084157\n",
            "Test set average loss: 0.6632\n",
            "\n",
            "Test set fa/fr: 0.4000\n",
            "\n",
            "test accuracy: 0.9197707736389685\n",
            "epoch: 86\n",
            "train accuracy: 0.9356072680905324\n",
            "Test set average loss: 0.6627\n",
            "\n",
            "Test set fa/fr: 0.2727\n",
            "\n",
            "test accuracy: 0.9598853868194842\n",
            "epoch: 87\n",
            "train accuracy: 0.9486770800127511\n",
            "Test set average loss: 0.6625\n",
            "\n",
            "Test set fa/fr: 0.3636\n",
            "\n",
            "test accuracy: 0.9570200573065902\n",
            "epoch: 88\n",
            "train accuracy: 0.9432578897035384\n",
            "Test set average loss: 0.6626\n",
            "\n",
            "Test set fa/fr: 0.1818\n",
            "\n",
            "test accuracy: 0.9627507163323782\n",
            "epoch: 89\n",
            "train accuracy: 0.9547338221230475\n",
            "Test set average loss: 0.6626\n",
            "\n",
            "Test set fa/fr: 0.0833\n",
            "\n",
            "test accuracy: 0.9627507163323782\n",
            "epoch: 90\n",
            "train accuracy: 0.9588779088300925\n",
            "Test set average loss: 0.6624\n",
            "\n",
            "Test set fa/fr: 0.0769\n",
            "\n",
            "test accuracy: 0.9598853868194842\n",
            "epoch: 91\n",
            "Train Epoch: 91\tLoss: 0.662974\tfa/fr: 0.200000\n",
            "train accuracy: 0.952821166719796\n",
            "Test set average loss: 0.6624\n",
            "\n",
            "Test set fa/fr: 0.4444\n",
            "\n",
            "test accuracy: 0.9627507163323782\n",
            "epoch: 92\n",
            "train accuracy: 0.9534587185208798\n",
            "Test set average loss: 0.6625\n",
            "\n",
            "Test set fa/fr: 0.6154\n",
            "\n",
            "test accuracy: 0.9398280802292264\n",
            "epoch: 93\n",
            "train accuracy: 0.9305068536818617\n",
            "Test set average loss: 0.6625\n",
            "\n",
            "Test set fa/fr: 0.0909\n",
            "\n",
            "test accuracy: 0.9656160458452722\n",
            "epoch: 94\n",
            "train accuracy: 0.9563277016257571\n",
            "Test set average loss: 0.6624\n",
            "\n",
            "Test set fa/fr: 0.4000\n",
            "\n",
            "test accuracy: 0.9598853868194842\n",
            "epoch: 95\n",
            "train accuracy: 0.952502390819254\n",
            "Test set average loss: 0.6626\n",
            "\n",
            "Test set fa/fr: 0.3333\n",
            "\n",
            "test accuracy: 0.9541547277936963\n",
            "epoch: 96\n",
            "train accuracy: 0.9509085113165445\n",
            "Test set average loss: 0.6626\n",
            "\n",
            "Test set fa/fr: 0.0625\n",
            "\n",
            "test accuracy: 0.9512893982808023\n",
            "epoch: 97\n",
            "train accuracy: 0.9474019764105833\n",
            "Test set average loss: 0.6624\n",
            "\n",
            "Test set fa/fr: 0.2000\n",
            "\n",
            "test accuracy: 0.9656160458452722\n",
            "epoch: 98\n",
            "train accuracy: 0.952502390819254\n",
            "Test set average loss: 0.6626\n",
            "\n",
            "Test set fa/fr: 0.5000\n",
            "\n",
            "test accuracy: 0.9398280802292264\n",
            "epoch: 99\n",
            "train accuracy: 0.932738284985655\n",
            "Test set average loss: 0.6626\n",
            "\n",
            "Test set fa/fr: 0.0714\n",
            "\n",
            "test accuracy: 0.9570200573065902\n",
            "epoch: 100\n",
            "train accuracy: 0.944851769206248\n",
            "Test set average loss: 0.6625\n",
            "\n",
            "Test set fa/fr: 0.1333\n",
            "\n",
            "test accuracy: 0.9512893982808023\n",
            "epoch: 101\n",
            "Train Epoch: 101\tLoss: 0.662670\tfa/fr: 0.000000\n",
            "train accuracy: 0.9505897354160026\n",
            "Test set average loss: 0.6625\n",
            "\n",
            "Test set fa/fr: 0.1667\n",
            "\n",
            "test accuracy: 0.9598853868194842\n",
            "epoch: 102\n",
            "train accuracy: 0.9493146318138349\n",
            "Test set average loss: 0.6625\n",
            "\n",
            "Test set fa/fr: 0.0833\n",
            "\n",
            "test accuracy: 0.9627507163323782\n",
            "epoch: 103\n",
            "train accuracy: 0.952502390819254\n",
            "Test set average loss: 0.6624\n",
            "\n",
            "Test set fa/fr: 0.1333\n",
            "\n",
            "test accuracy: 0.9512893982808023\n",
            "epoch: 104\n",
            "train accuracy: 0.9537774944214218\n",
            "Test set average loss: 0.6624\n",
            "\n",
            "Test set fa/fr: 0.3636\n",
            "\n",
            "test accuracy: 0.9570200573065902\n",
            "epoch: 105\n",
            "train accuracy: 0.960471788332802\n",
            "Test set average loss: 0.6624\n",
            "\n",
            "Test set fa/fr: 0.1818\n",
            "\n",
            "test accuracy: 0.9627507163323782\n",
            "epoch: 106\n",
            "train accuracy: 0.9569652534268409\n",
            "Test set average loss: 0.6625\n",
            "\n",
            "Test set fa/fr: 0.0909\n",
            "\n",
            "test accuracy: 0.9656160458452722\n",
            "epoch: 107\n",
            "train accuracy: 0.9576028052279247\n",
            "Test set average loss: 0.6625\n",
            "\n",
            "Test set fa/fr: 0.1111\n",
            "\n",
            "test accuracy: 0.9713467048710601\n",
            "epoch: 108\n",
            "train accuracy: 0.9359260439910743\n",
            "Test set average loss: 0.6625\n",
            "\n",
            "Test set fa/fr: 0.1538\n",
            "\n",
            "test accuracy: 0.9570200573065902\n",
            "epoch: 109\n",
            "train accuracy: 0.9483583041122091\n",
            "Test set average loss: 0.6623\n",
            "\n",
            "Test set fa/fr: 0.3000\n",
            "\n",
            "test accuracy: 0.9627507163323782\n",
            "epoch: 110\n",
            "train accuracy: 0.9595154606311763\n",
            "Test set average loss: 0.6624\n",
            "\n",
            "Test set fa/fr: 0.2000\n",
            "\n",
            "test accuracy: 0.9656160458452722\n",
            "epoch: 111\n",
            "Train Epoch: 111\tLoss: 0.662655\tfa/fr: 0.500000\n",
            "train accuracy: 0.9470832005100415\n",
            "Test set average loss: 0.6625\n",
            "\n",
            "Test set fa/fr: 0.5556\n",
            "\n",
            "test accuracy: 0.9598853868194842\n",
            "epoch: 112\n",
            "train accuracy: 0.9556901498246733\n",
            "Test set average loss: 0.6626\n",
            "\n",
            "Test set fa/fr: 0.3333\n",
            "\n",
            "test accuracy: 0.9656160458452722\n",
            "epoch: 113\n",
            "train accuracy: 0.9515460631176283\n",
            "Test set average loss: 0.6626\n",
            "\n",
            "Test set fa/fr: 0.4167\n",
            "\n",
            "test accuracy: 0.9512893982808023\n",
            "epoch: 114\n",
            "train accuracy: 0.9537774944214218\n",
            "Test set average loss: 0.6625\n",
            "\n",
            "Test set fa/fr: 0.2857\n",
            "\n",
            "test accuracy: 0.9484240687679083\n",
            "epoch: 115\n",
            "train accuracy: 0.9426203379024546\n",
            "Test set average loss: 0.6625\n",
            "\n",
            "Test set fa/fr: 0.3000\n",
            "\n",
            "test accuracy: 0.9627507163323782\n",
            "epoch: 116\n",
            "train accuracy: 0.9556901498246733\n",
            "Test set average loss: 0.6624\n",
            "\n",
            "Test set fa/fr: 0.3000\n",
            "\n",
            "test accuracy: 0.9627507163323782\n",
            "epoch: 117\n",
            "train accuracy: 0.9601530124322601\n",
            "Test set average loss: 0.6623\n",
            "\n",
            "Test set fa/fr: 0.2727\n",
            "\n",
            "test accuracy: 0.9598853868194842\n",
            "epoch: 118\n",
            "train accuracy: 0.9298693018807778\n",
            "Test set average loss: 0.6625\n",
            "\n",
            "Test set fa/fr: 0.2353\n",
            "\n",
            "test accuracy: 0.9398280802292264\n",
            "epoch: 119\n",
            "train accuracy: 0.9292317500796939\n",
            "Test set average loss: 0.6624\n",
            "\n",
            "Test set fa/fr: 0.2000\n",
            "\n",
            "test accuracy: 0.9484240687679083\n",
            "epoch: 120\n",
            "train accuracy: 0.9305068536818617\n",
            "Test set average loss: 0.6625\n",
            "\n",
            "Test set fa/fr: 0.3125\n",
            "\n",
            "test accuracy: 0.9398280802292264\n",
            "epoch: 121\n",
            "Train Epoch: 121\tLoss: 0.663594\tfa/fr: 1.000000\n",
            "train accuracy: 0.9496334077143768\n",
            "Test set average loss: 0.6626\n",
            "\n",
            "Test set fa/fr: 0.1111\n",
            "\n",
            "test accuracy: 0.9426934097421203\n",
            "epoch: 122\n",
            "train accuracy: 0.9467644246094995\n",
            "Test set average loss: 0.6626\n",
            "\n",
            "Test set fa/fr: 0.2000\n",
            "\n",
            "test accuracy: 0.9484240687679083\n",
            "epoch: 123\n",
            "train accuracy: 0.9493146318138349\n",
            "Test set average loss: 0.6625\n",
            "\n",
            "Test set fa/fr: 0.4444\n",
            "\n",
            "test accuracy: 0.9627507163323782\n",
            "epoch: 124\n",
            "train accuracy: 0.952502390819254\n",
            "Test set average loss: 0.6625\n",
            "\n",
            "Test set fa/fr: 0.2308\n",
            "\n",
            "test accuracy: 0.9541547277936963\n",
            "epoch: 125\n",
            "train accuracy: 0.9509085113165445\n",
            "Test set average loss: 0.6625\n",
            "\n",
            "Test set fa/fr: 0.1250\n",
            "\n",
            "test accuracy: 0.9484240687679083\n",
            "epoch: 126\n",
            "train accuracy: 0.9489958559132929\n",
            "Test set average loss: 0.6626\n",
            "\n",
            "Test set fa/fr: 0.2353\n",
            "\n",
            "test accuracy: 0.9398280802292264\n",
            "epoch: 127\n",
            "train accuracy: 0.9556901498246733\n",
            "Test set average loss: 0.6626\n",
            "\n",
            "Test set fa/fr: 0.3636\n",
            "\n",
            "test accuracy: 0.9570200573065902\n",
            "epoch: 128\n",
            "train accuracy: 0.9623844437360536\n",
            "Test set average loss: 0.6624\n",
            "\n",
            "Test set fa/fr: 0.4000\n",
            "\n",
            "test accuracy: 0.9598853868194842\n",
            "epoch: 129\n",
            "train accuracy: 0.9617468919349698\n",
            "Test set average loss: 0.6624\n",
            "\n",
            "Test set fa/fr: 0.3000\n",
            "\n",
            "test accuracy: 0.9627507163323782\n",
            "epoch: 130\n",
            "train accuracy: 0.9534587185208798\n",
            "Test set average loss: 0.6627\n",
            "\n",
            "Test set fa/fr: 0.6667\n",
            "\n",
            "test accuracy: 0.9570200573065902\n",
            "epoch: 131\n",
            "Train Epoch: 131\tLoss: 0.662932\tfa/fr: 1.000000\n",
            "train accuracy: 0.9518648390181702\n",
            "Test set average loss: 0.6626\n",
            "\n",
            "Test set fa/fr: 0.2727\n",
            "\n",
            "test accuracy: 0.9598853868194842\n",
            "epoch: 132\n",
            "train accuracy: 0.9477207523111253\n",
            "Test set average loss: 0.6625\n",
            "\n",
            "Test set fa/fr: 0.3000\n",
            "\n",
            "test accuracy: 0.9627507163323782\n",
            "epoch: 133\n",
            "train accuracy: 0.9467644246094995\n",
            "Test set average loss: 0.6624\n",
            "\n",
            "Test set fa/fr: 1.0000\n",
            "\n",
            "test accuracy: 0.9426934097421203\n",
            "epoch: 134\n",
            "train accuracy: 0.9356072680905324\n",
            "Test set average loss: 0.6627\n",
            "\n",
            "Test set fa/fr: 0.0714\n",
            "\n",
            "test accuracy: 0.9570200573065902\n",
            "epoch: 135\n",
            "train accuracy: 0.952821166719796\n",
            "Test set average loss: 0.6629\n",
            "\n",
            "Test set fa/fr: 0.0667\n",
            "\n",
            "test accuracy: 0.9541547277936963\n",
            "epoch: 136\n",
            "train accuracy: 0.9426203379024546\n",
            "Test set average loss: 0.6625\n",
            "\n",
            "Test set fa/fr: 0.0769\n",
            "\n",
            "test accuracy: 0.9598853868194842\n",
            "epoch: 137\n",
            "train accuracy: 0.9544150462225056\n",
            "Test set average loss: 0.6624\n",
            "\n",
            "Test set fa/fr: 0.3333\n",
            "\n",
            "test accuracy: 0.9541547277936963\n",
            "epoch: 138\n",
            "train accuracy: 0.952502390819254\n",
            "Test set average loss: 0.6624\n",
            "\n",
            "Test set fa/fr: 0.4444\n",
            "\n",
            "test accuracy: 0.9627507163323782\n",
            "epoch: 139\n",
            "train accuracy: 0.9588779088300925\n",
            "Test set average loss: 0.6623\n",
            "\n",
            "Test set fa/fr: 0.3000\n",
            "\n",
            "test accuracy: 0.9627507163323782\n",
            "epoch: 140\n",
            "train accuracy: 0.9582403570290086\n",
            "Test set average loss: 0.6625\n",
            "\n",
            "Test set fa/fr: 1.5714\n",
            "\n",
            "test accuracy: 0.9484240687679083\n",
            "epoch: 141\n",
            "Train Epoch: 141\tLoss: 0.662940\tfa/fr: 4.000000\n",
            "train accuracy: 0.9464456487089576\n",
            "Test set average loss: 0.6626\n",
            "\n",
            "Test set fa/fr: 0.3333\n",
            "\n",
            "test accuracy: 0.9656160458452722\n",
            "epoch: 142\n",
            "train accuracy: 0.9550525980235894\n",
            "Test set average loss: 0.6623\n",
            "\n",
            "Test set fa/fr: 0.0833\n",
            "\n",
            "test accuracy: 0.9627507163323782\n",
            "epoch: 143\n",
            "train accuracy: 0.9537774944214218\n",
            "Test set average loss: 0.6624\n",
            "\n",
            "Test set fa/fr: 0.0909\n",
            "\n",
            "test accuracy: 0.9656160458452722\n",
            "epoch: 144\n",
            "train accuracy: 0.9560089257252151\n",
            "Test set average loss: 0.6625\n",
            "\n",
            "Test set fa/fr: 0.0000\n",
            "\n",
            "test accuracy: 0.9684813753581661\n",
            "epoch: 145\n",
            "train accuracy: 0.9537774944214218\n",
            "Test set average loss: 0.6625\n",
            "\n",
            "Test set fa/fr: 0.1111\n",
            "\n",
            "test accuracy: 0.9713467048710601\n",
            "epoch: 146\n",
            "train accuracy: 0.9534587185208798\n",
            "Test set average loss: 0.6624\n",
            "\n",
            "Test set fa/fr: 0.3846\n",
            "\n",
            "test accuracy: 0.9484240687679083\n",
            "epoch: 147\n",
            "train accuracy: 0.9486770800127511\n",
            "Test set average loss: 0.6624\n",
            "\n",
            "Test set fa/fr: 0.6364\n",
            "\n",
            "test accuracy: 0.9484240687679083\n",
            "epoch: 148\n",
            "train accuracy: 0.9560089257252151\n",
            "Test set average loss: 0.6626\n",
            "\n",
            "Test set fa/fr: 0.1333\n",
            "\n",
            "test accuracy: 0.9512893982808023\n",
            "epoch: 149\n",
            "train accuracy: 0.952502390819254\n",
            "Test set average loss: 0.6624\n",
            "\n",
            "Test set fa/fr: 0.0000\n",
            "\n",
            "test accuracy: 0.9684813753581661\n",
            "epoch: 150\n",
            "train accuracy: 0.9445329933057061\n",
            "Test set average loss: 0.6623\n",
            "\n",
            "Test set fa/fr: 0.2500\n",
            "\n",
            "test accuracy: 0.9713467048710601\n",
            "epoch: 151\n",
            "Train Epoch: 151\tLoss: 0.662615\tfa/fr: 0.000000\n",
            "train accuracy: 0.9489958559132929\n",
            "Test set average loss: 0.6623\n",
            "\n",
            "Test set fa/fr: 0.1818\n",
            "\n",
            "test accuracy: 0.9627507163323782\n",
            "epoch: 152\n",
            "train accuracy: 0.9540962703219636\n",
            "Test set average loss: 0.6624\n",
            "\n",
            "Test set fa/fr: 0.0833\n",
            "\n",
            "test accuracy: 0.9627507163323782\n",
            "epoch: 153\n",
            "train accuracy: 0.9560089257252151\n",
            "Test set average loss: 0.6623\n",
            "\n",
            "Test set fa/fr: 0.2222\n",
            "\n",
            "test accuracy: 0.9684813753581661\n",
            "epoch: 154\n",
            "train accuracy: 0.9483583041122091\n",
            "Test set average loss: 0.6625\n",
            "\n",
            "Test set fa/fr: 0.0000\n",
            "\n",
            "test accuracy: 0.9598853868194842\n",
            "epoch: 155\n",
            "train accuracy: 0.9556901498246733\n",
            "Test set average loss: 0.6623\n",
            "\n",
            "Test set fa/fr: 0.4286\n",
            "\n",
            "test accuracy: 0.9713467048710601\n",
            "epoch: 156\n",
            "train accuracy: 0.9461268728084157\n",
            "Test set average loss: 0.6623\n",
            "\n",
            "Test set fa/fr: 0.1333\n",
            "\n",
            "test accuracy: 0.9512893982808023\n",
            "epoch: 157\n",
            "train accuracy: 0.9499521836149187\n",
            "Test set average loss: 0.6624\n",
            "\n",
            "Test set fa/fr: 0.5000\n",
            "\n",
            "test accuracy: 0.9570200573065902\n",
            "epoch: 158\n",
            "train accuracy: 0.9569652534268409\n",
            "Test set average loss: 0.6625\n",
            "\n",
            "Test set fa/fr: 0.3077\n",
            "\n",
            "test accuracy: 0.9512893982808023\n",
            "epoch: 159\n",
            "train accuracy: 0.9550525980235894\n",
            "Test set average loss: 0.6626\n",
            "\n",
            "Test set fa/fr: 0.0769\n",
            "\n",
            "test accuracy: 0.9598853868194842\n",
            "epoch: 160\n",
            "train accuracy: 0.9582403570290086\n",
            "Test set average loss: 0.6625\n",
            "\n",
            "Test set fa/fr: 0.0833\n",
            "\n",
            "test accuracy: 0.9627507163323782\n",
            "epoch: 161\n",
            "Train Epoch: 161\tLoss: 0.662688\tfa/fr: 0.250000\n",
            "train accuracy: 0.9502709595154606\n",
            "Test set average loss: 0.6627\n",
            "\n",
            "Test set fa/fr: 0.1250\n",
            "\n",
            "test accuracy: 0.9484240687679083\n",
            "epoch: 162\n",
            "train accuracy: 0.9521836149187122\n",
            "Test set average loss: 0.6624\n",
            "\n",
            "Test set fa/fr: 0.1250\n",
            "\n",
            "test accuracy: 0.9742120343839542\n",
            "epoch: 163\n",
            "train accuracy: 0.9518648390181702\n",
            "Test set average loss: 0.6624\n",
            "\n",
            "Test set fa/fr: 0.0000\n",
            "\n",
            "test accuracy: 0.9684813753581661\n",
            "epoch: 164\n",
            "train accuracy: 0.9642970991393051\n",
            "Test set average loss: 0.6625\n",
            "\n",
            "Test set fa/fr: 0.0769\n",
            "\n",
            "test accuracy: 0.9598853868194842\n",
            "epoch: 165\n",
            "train accuracy: 0.9534587185208798\n",
            "Test set average loss: 0.6626\n",
            "\n",
            "Test set fa/fr: 0.0000\n",
            "\n",
            "test accuracy: 0.9627507163323782\n",
            "epoch: 166\n",
            "train accuracy: 0.9601530124322601\n",
            "Test set average loss: 0.6623\n",
            "\n",
            "Test set fa/fr: 0.4000\n",
            "\n",
            "test accuracy: 0.9598853868194842\n",
            "epoch: 167\n",
            "train accuracy: 0.952821166719796\n",
            "Test set average loss: 0.6626\n",
            "\n",
            "Test set fa/fr: 0.1429\n",
            "\n",
            "test accuracy: 0.9541547277936963\n",
            "epoch: 168\n",
            "train accuracy: 0.9544150462225056\n",
            "Test set average loss: 0.6624\n",
            "\n",
            "Test set fa/fr: 0.6000\n",
            "\n",
            "test accuracy: 0.9541547277936963\n",
            "epoch: 169\n",
            "train accuracy: 0.9467644246094995\n",
            "Test set average loss: 0.6624\n",
            "\n",
            "Test set fa/fr: 0.3333\n",
            "\n",
            "test accuracy: 0.9541547277936963\n",
            "epoch: 170\n",
            "train accuracy: 0.956646477526299\n",
            "Test set average loss: 0.6624\n",
            "\n",
            "Test set fa/fr: 0.0000\n",
            "\n",
            "test accuracy: 0.9799426934097422\n",
            "epoch: 171\n",
            "Train Epoch: 171\tLoss: 0.662620\tfa/fr: 1.500000\n",
            "train accuracy: 0.9572840293273829\n",
            "Test set average loss: 0.6624\n",
            "\n",
            "Test set fa/fr: 0.1818\n",
            "\n",
            "test accuracy: 0.9627507163323782\n",
            "epoch: 172\n",
            "train accuracy: 0.960790564233344\n",
            "Test set average loss: 0.6624\n",
            "\n",
            "Test set fa/fr: 0.0000\n",
            "\n",
            "test accuracy: 0.9684813753581661\n",
            "epoch: 173\n",
            "train accuracy: 0.9534587185208798\n",
            "Test set average loss: 0.6624\n",
            "\n",
            "Test set fa/fr: 0.0000\n",
            "\n",
            "test accuracy: 0.9742120343839542\n",
            "epoch: 174\n",
            "train accuracy: 0.9591966847306344\n",
            "Test set average loss: 0.6624\n",
            "\n",
            "Test set fa/fr: 0.0000\n",
            "\n",
            "test accuracy: 0.9713467048710601\n",
            "epoch: 175\n",
            "train accuracy: 0.9480395282116671\n",
            "Test set average loss: 0.6627\n",
            "\n",
            "Test set fa/fr: 0.1053\n",
            "\n",
            "test accuracy: 0.9398280802292264\n",
            "epoch: 176\n",
            "train accuracy: 0.9403889065986611\n",
            "Test set average loss: 0.6624\n",
            "\n",
            "Test set fa/fr: 0.0000\n",
            "\n",
            "test accuracy: 0.9484240687679083\n",
            "epoch: 177\n",
            "train accuracy: 0.9458080969078738\n",
            "Test set average loss: 0.6624\n",
            "\n",
            "Test set fa/fr: 0.1250\n",
            "\n",
            "test accuracy: 0.9484240687679083\n",
            "epoch: 178\n",
            "train accuracy: 0.9537774944214218\n",
            "Test set average loss: 0.6626\n",
            "\n",
            "Test set fa/fr: 0.1000\n",
            "\n",
            "test accuracy: 0.9684813753581661\n",
            "epoch: 179\n",
            "train accuracy: 0.9611093401338858\n",
            "Test set average loss: 0.6625\n",
            "\n",
            "Test set fa/fr: 0.0909\n",
            "\n",
            "test accuracy: 0.9656160458452722\n",
            "epoch: 180\n",
            "train accuracy: 0.9576028052279247\n",
            "Test set average loss: 0.6623\n",
            "\n",
            "Test set fa/fr: 0.1250\n",
            "\n",
            "test accuracy: 0.9742120343839542\n",
            "epoch: 181\n",
            "Train Epoch: 181\tLoss: 0.662649\tfa/fr: 0.000000\n",
            "train accuracy: 0.9585591329295505\n",
            "Test set average loss: 0.6625\n",
            "\n",
            "Test set fa/fr: 0.1818\n",
            "\n",
            "test accuracy: 0.9627507163323782\n",
            "epoch: 182\n",
            "train accuracy: 0.9601530124322601\n",
            "Test set average loss: 0.6624\n",
            "\n",
            "Test set fa/fr: 0.1111\n",
            "\n",
            "test accuracy: 0.9713467048710601\n",
            "epoch: 183\n",
            "train accuracy: 0.960790564233344\n",
            "Test set average loss: 0.6626\n",
            "\n",
            "Test set fa/fr: 0.2000\n",
            "\n",
            "test accuracy: 0.9656160458452722\n",
            "epoch: 184\n",
            "train accuracy: 0.9588779088300925\n",
            "Test set average loss: 0.6628\n",
            "\n",
            "Test set fa/fr: 0.0625\n",
            "\n",
            "test accuracy: 0.9512893982808023\n",
            "epoch: 185\n",
            "train accuracy: 0.9426203379024546\n",
            "Test set average loss: 0.6625\n",
            "\n",
            "Test set fa/fr: 0.1333\n",
            "\n",
            "test accuracy: 0.9512893982808023\n",
            "epoch: 186\n",
            "train accuracy: 0.9512272872170864\n",
            "Test set average loss: 0.6625\n",
            "\n",
            "Test set fa/fr: 0.1538\n",
            "\n",
            "test accuracy: 0.9570200573065902\n",
            "epoch: 187\n",
            "train accuracy: 0.9633407714376793\n",
            "Test set average loss: 0.6625\n",
            "\n",
            "Test set fa/fr: 0.2222\n",
            "\n",
            "test accuracy: 0.9684813753581661\n",
            "epoch: 188\n",
            "train accuracy: 0.9496334077143768\n",
            "Test set average loss: 0.6627\n",
            "\n",
            "Test set fa/fr: 0.2222\n",
            "\n",
            "test accuracy: 0.9684813753581661\n",
            "epoch: 189\n",
            "train accuracy: 0.9489958559132929\n",
            "Test set average loss: 0.6624\n",
            "\n",
            "Test set fa/fr: 0.1818\n",
            "\n",
            "test accuracy: 0.9627507163323782\n",
            "epoch: 190\n",
            "train accuracy: 0.9515460631176283\n",
            "Test set average loss: 0.6627\n",
            "\n",
            "Test set fa/fr: 0.3636\n",
            "\n",
            "test accuracy: 0.9570200573065902\n",
            "epoch: 191\n",
            "Train Epoch: 191\tLoss: 0.662603\tfa/fr: 1.000000\n",
            "train accuracy: 0.9576028052279247\n",
            "Test set average loss: 0.6624\n",
            "\n",
            "Test set fa/fr: 0.0909\n",
            "\n",
            "test accuracy: 0.9656160458452722\n",
            "epoch: 192\n",
            "train accuracy: 0.9438954415046222\n",
            "Test set average loss: 0.6624\n",
            "\n",
            "Test set fa/fr: 0.1250\n",
            "\n",
            "test accuracy: 0.9484240687679083\n",
            "epoch: 193\n",
            "train accuracy: 0.9534587185208798\n",
            "Test set average loss: 0.6625\n",
            "\n",
            "Test set fa/fr: 0.0625\n",
            "\n",
            "test accuracy: 0.9512893982808023\n",
            "epoch: 194\n",
            "train accuracy: 0.9537774944214218\n",
            "Test set average loss: 0.6625\n",
            "\n",
            "Test set fa/fr: 0.1333\n",
            "\n",
            "test accuracy: 0.9512893982808023\n",
            "epoch: 195\n",
            "train accuracy: 0.9518648390181702\n",
            "Test set average loss: 0.6625\n",
            "\n",
            "Test set fa/fr: 0.0000\n",
            "\n",
            "test accuracy: 0.9742120343839542\n",
            "epoch: 196\n",
            "train accuracy: 0.9534587185208798\n",
            "Test set average loss: 0.6627\n",
            "\n",
            "Test set fa/fr: 0.1333\n",
            "\n",
            "test accuracy: 0.9512893982808023\n",
            "epoch: 197\n",
            "train accuracy: 0.9470832005100415\n",
            "Test set average loss: 0.6626\n",
            "\n",
            "Test set fa/fr: 0.5000\n",
            "\n",
            "test accuracy: 0.9570200573065902\n",
            "epoch: 198\n",
            "train accuracy: 0.9569652534268409\n",
            "Test set average loss: 0.6626\n",
            "\n",
            "Test set fa/fr: 0.1818\n",
            "\n",
            "test accuracy: 0.9627507163323782\n",
            "epoch: 199\n",
            "train accuracy: 0.960790564233344\n",
            "Test set average loss: 0.6624\n",
            "\n",
            "Test set fa/fr: 0.0000\n",
            "\n",
            "test accuracy: 0.9684813753581661\n",
            "Saved model at last epoch\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UAsyVDVtPa5V"
      },
      "source": [
        "### You can see metrics here: https://wandb.ai/maxthehuman/kws-implementation/runs/1svru9b1?workspace=user-maxthehuman"
      ]
    }
  ]
}